task: llm-sft
base_model: Qwen/Qwen2.5-3B
project_name: fl-switzerland-sft-1-bottom20
log: all
backend: local

wandb:
  run_name: fl-switzerland-sft-1-bottom20
  log_model: true
  tags: ["federated-learning", "sft", "switzerland", "bottom20"]

data:
  path: TheFinAI/MED_SYN1_SWITZERLAND_BOTTOM_train
  train_split: train
  valid_split: null
  chat_template: tokenizer
  column_mapping:
    text_column: entries

params:
  block_size: 256
  model_max_length: 42000
  epochs: 100
  batch_size: 1
  lr: 0.0005
  peft: true
  lora_r: 16
  lora_alpha: 32
  lora_dropout: 0
  quantization: int4
  target_modules: all-linear
  padding: right
  optimizer: adamw_torch
  scheduler: cosine
  gradient_accumulation: 4
  mixed_precision: bf16
  merge_adapter: true

hub:
  username: ${HF_USERNAME}
  token: ${HF_TOKEN}
  push_to_hub: true
