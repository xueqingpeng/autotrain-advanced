task: llm-dpo
base_model: TheFinAI/Fino1-8B_v2
project_name: Fino1-8B-dpo-qlora2
log: tensorboard
backend: local

data:
        path: TheFinAI/Fino1_RL_dpo_train
        train_split: train
        valid_split: null
        chat_template: chatml
        column_mapping:
                text_column: chosen
                rejected_text_column: rejected
                prompt_text_column: prompt

params:
        block_size: 1024
        model_max_length: 17000
        max_prompt_length: 15000
        epochs: 3
        batch_size: 2
        lr: 1e-6
        peft: true
        quantization: int4
        target_modules: all-linear
        padding: right
        optimizer: adamw_torch
        scheduler: linear
        gradient_accumulation: 4
        mixed_precision: fp16

hub:
        username: ${HF_USERNAME}
        token: ${HF_TOKEN}
        push_to_hub: true
